社区需要维护一个镜像源，且要保证镜像源的仓库版本是最新的。

### 基本流程

首先coordinator启动等待10min，到时间有一定数量的worker连接之后固定哈希，确定好哈希环结构之后coordinator开始计算每一个worker与repo之间的哈希对应，并且记录下来。

在coor端有维护一个map对应保存worker和urls，在此充当一个**缓冲区**的作用。每次worker向coor发送心跳包，coor会解析获取到workerID，然后在对应的map中查找缓冲区是否为空。是 -- respon返回、清空缓冲区； 否 -- 正常返回respon

之后worker通过解析respon获取一个List，会通过自己维护的urls List对本地仓库进行增加和删除。

### 心跳机制

的设计主要是worker定期发送心跳包给coordinator，由coordinator去累计一个接收到的心跳包sum，然后每次通过这个总和去判断哪个worker已经很久没有发送心跳包了（设置一个最大限度的查值sumMax）

然后将发送心跳包以及心跳验证的时间频率增大，让心跳包发的频率快点。当有一个worker挂掉时，就可以通过心跳包的response，由coordinator向worker发送add/del的仓库的list通知。

### Coordinator数据结构

1、git clone到磁盘，内存中用**git tree**构建上游源仓库

2、管理worker用**bitmap**

3、add_repo/delete_repo-> fetch upstream_urls_repo获得的增加/删减的仓库，根据hash算出对应的worker，告诉worker添加对该repo的监听

### 仓库下发worker机制

一致性哈希算法来分配url对应worker

**用一致性哈希的原因**：由于在分布式集群中worker节点的个数会不定时调整（增加n个worker或n个worker挂机的情况），如果采用常规哈希，在面对节点数量变化时选择重新去仓库列表源Coordinator中大规模进行仓库的重新分配，效率会很低且耗时间。

**解决worker负载不均的问题**（当worker数量少时，有种情况是如果当前workerA挂了，那么原本workerA维护的n个仓库将全部由顺时针的下个workerB进行维护，导致负载不均）：在一致性哈希的基础上，加入一个节点到环上其实是被映射成了多个。

**hash过程**：计算worker的hash（在coor中用bitmap去管理worker，计算则用的是map的index），放在环上。

计算仓库（使用仓库URL）hash，对哈希值进行判断-> 顺时针寻找到的第一个节点就是对应的worker

##### 插入新worker后，旧worker.next上的仓库是否需要取消其在worker上的维护？ => 需要

【coordinator修改映射】 (1by1事务) delete hash in new_worker.next => add hash in new_worker

【send to worker修改worker内部维护的repo list】send rpc -> [new_worker]add_repo、[new_worker.next]delete_repo

##### 防止repo抖动(thrashing)处理

1. coordinator初次启动时，先等待一段时间(10min)，小批次分发任务，逐步增加
2. 之后每次coordinator启动时，先读取缓存信息(active workers等)，使用之
3. 【coordinator对每一个worker挂机，先等待一段时间(10min)】，无响应才将repo remove重新分配给其他worker。**超时worker未上线**：并将这些repo在对应的worker中的优先级pri值设为最小（**防止优先级饥饿**）

**关于组件之间的通信**：统一使用远程过程调用（grpc），在coordinator本地注册处理函数，worker发送对应请求即可触发对应函数

**磁盘检测机制**：worker每次clone前会检查磁盘容量，>85即停止clone，将这些url返回给coor，coor对url后缀加上固定字符后，重新计算md5值。

###  POLL interval 自适应算法

【优先级和优先级队列结合】

保持最近更新的仓库优先级较高（数值越小优先级越高），通过每次+step**防止优先级饥饿问题**

worker_main_loop：

​		priority.queue.pop【从优先队列delete_min】-> 

​			push_git_queue【放入任务队列】-> 

​				get_repo_priority【计算新优先级】-> 

​					priority.queue.push 【放回优先级队列】

new_10_threads：git_queue.pop【从任务队列中取任务进行处理】

```c
STEP_SECONDS = 2592000 // 每个步骤的时间间隔

func get_repo_priority(git_repo, old_pri) {
    mirror_dir = find .git file
	step = (git_repo.clone_fail_cnt + 1) * cbrt(STEP_SECONDS)  // clone_fail
    if(mirror_dir == null) {
        return old_pri + step  // 仓库未克隆
    }
    return cal_priority(mirror_dir, old_dir, git_repo)
}

func cal_priority(mirror_dir, old_pri, git_repo) {
    last_commit_time = ...
    step = (git_repo.fetch_fail_cnt + 1) * cbrt(STEP_SECONDS) // fetch_fail
    if(last_commit_time == 0) {
        return old_pri + step  // 没进行过提交
    }
    
    interval = nowTime - last_commit_time
    if(interval <= 0) {
        
        return old_pri + step
    }
    return old_pri + cbrt(interval)
}
```


