## 数据结构

### 1、Slice

#### 底层实现

- `array`: 指向底层数组的指针，占用 8 个字节；
- `len`: 切片的长度，占用 8 个字节；
- `cap`: 切片的容量，`cap` 总是大于等于 `len` 的，占用 8 个字节。

#### slice扩容

**注意：这是1.18后优化的扩容措施！**

> golang中使用append函数来对slice进行扩容操作，append函数可以接受一个或多个元素作为参数，并返回一个新的slice。golang中使用make函数来创建一个指定长度和容量的slice，make函数可以接受一个类型、一个长度和一个可选的容量作为参数，并返回一个新的slice。

- golang中对slice的扩容策略取决于slice的元素类型和原始容量。一般来说，有以下几种情况：
  - 如果新扩容容量**大于当前容量的两倍**，则按**新扩容容量**进行分配。
  - 如果当前容量**小于256**，则按**当前容量的两倍**进行分配。
  - 如果当前容量**大于等于256**，那么会进入一个循环，每次循环都会增加 (当前容量 + 3 ✖️ 256) / 4 的容量，这条公式意味着从 2 倍扩容到 1.25 倍扩容的**平滑过渡**，如果循环过程中发生整数溢出，则将扩容后的容量置为期望容量。
  - 如果初始容量为0，则按目标容量进行分配。
- golang中对slice的扩容操作还会考虑**内存对齐**和**池化技术**，以提高内存访问效率和减少内存碎片。具体来说，有以下几个步骤：
  - 根据元素类型和新扩容容量计算出所需的内存大小。
  - 根据内存对齐规则调整内存大小，使其能够被8或16整除。
  - 根据内存池技术从不同大小的内存块中分配合适的内存空间。
  - 根据实际分配的内存空间计算出最终的切片容量。

#### slice 深拷贝和浅拷贝

浅拷贝是指在复制对象时，只复制对象本身和其中包含的基本类型数据，而**不会复制对象所引用的其他对象。**

也就是说，在浅拷贝中，复制出的新对象与原对象共享同一些引用对象。因此，如果修改了其中一个对象中的引用对象，另一个对象也会随之改变。

深拷贝则意味着在复制对象时，除了复制对象本身和其中包含的基本类型数据外，还会递归地复制对象所引用的其他对象。

也就是说，在深拷贝中，复制出的新对象和原对象是完全独立的，它们之间没有任何引用关系。因此，即使修改其中一个对象中的引用对象，另一个对象也不会受到影响。

- 实现**深拷贝**的方式：

​	copy 函数；
​	遍历 slice 再赋值。

- 实现**浅拷贝**的方式：

​	默认的赋值操作。

#### append是并发安全的吗？

切片本身**不是**并发安全的，如果多个goroutine同时对同一个切片进行读写操作，可能会导致数据竞争和不一致。因此，需要使用同步机制来保证并发安全，例如**使用sync.Mutex或者channel**等。

- 使用sync.Mutex来对切片的写入操作进行加锁和解锁，从而避免数据竞争。这种方法比较简单，但是会增加锁的开销和竞争。
- 使用不同的切片来存储不同goroutine产生的结果，并在最后合并到一个切片中。这种方法比较复杂，但是可以减少锁的使用和冲突。

> - 如果参数的数量是固定的，可以预先分配切片的大小，并让每个goroutine写入不同的位置，从而避免数据竞争。
> - 切片是否是指针类型并不影响并发安全性，关键在于是否对同一块内存进行读写操作。
> - 如果使用通道来传递结果，需要注意通道的缓冲大小和关闭时机，以及如何处理错误和异常情况。

### 2、Map

#### 底层实现

map 是一个 kv 对集合。底层使用 hash table，用链表来解决冲突 ，出现冲突时，不是每一个 key 都申请一个结构通过链表串起来，而是以 bmap 为最小粒度挂载，一个 bmap 可以放 8 个 kv。在哈希函数的选择上，会在程序启动时，检测 cpu 是否支持 aes，如果支持，则使用 aes hash，否则使用 memhash。每个 map 的底层结构是 hmap，是有若干个结构为 bmap 的 bucket 组成的数组。每个 bucket 底层都采用链表结构。

- 哈希表（**hmap**）：这是一个结构体，它存储了Map的元数据，例如元素数量、哈希种子、哈希桶数组的指针等。
- 哈希桶（**bmap**）：这是一个数组，它存储了8个键值对和一些控制信息，例如哈希值的高8位、溢出桶的指针等。
- 溢出桶（**bmap**）：这是一个链表，当一个 bmap 存放满之后，overflow 会指向一个溢出桶——它用来存储哈希冲突导致无法放入哈希桶的键值对。
- 键值对（**key-value pair**）：这是一种动态分配的内存空间，它用来存储具体的键和值。



##### hmap

```go
// $GOROOT/src/runtime/map.go
type hmap struct {
    count     int     // 代表哈希表中的元素个数，调用 len(map) 时，返回的就是该字段值。
    flags     uint8   // 状态标志（是否处于正在写入的状态等）
    B         uint8   // buckets 的对数。如果 B = 5，则 buckets 数组的长度 = 2^B = 32，意味着有 32 个桶。
    noverflow uint16  // 溢出桶的数量
    hash0     uint32  // 生成 hash 的随机数种子

    // 指向 buckets 数组的指针，数组大小为 2^B，如果元素个数为 0，它为 nil。
    // buckets 数组中每个元素都是 bmap 结构
    buckets    unsafe.Pointer
    // 如果发生扩容，oldbuckets 是指向老的 buckets 数组的指针，
    // 老的 buckets 数组大小是新的 buckets 的 1/2，
    // 非扩容状态下，它为 nil。
    oldbuckets unsafe.Pointer
    nevacuate  uintptr        // 表示扩容进度，小于此地址的 buckets 代表已搬迁完成。

    extra *mapextra // 存储一些额外信息。
}
```

##### bmap

```go
// $GOROOT/src/runtime/map.go
// A bucket for a Go map.
type bmap struct {
    // 长度为 8 的数组
    // 用来快速定位 key 是否在这个 bmap 中
    // 一个桶最多有 8 个槽位，如果 key 计算出来的 tophash 值在 tophash 数组中，则代表该 key 在这个桶中
    tophash [bucketCnt]uint8
}
```

每个 bmap 底层都采用链表结构。bmap 就是我们常说的 “桶”，一个桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果的低 B 位是相同的。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有 8 个位置）。也就是说，tophash 字段存储了 key 哈希值的高 8 位。

此外，tophash 字段还会存储一些状态值，用来表明当前桶单元状态，这些状态值都是小于 minTopHash。

为了避免 key 哈希值的高 8 位值和这些状态值相等，产生混淆情况，所以当 key 哈希值高 8 位小于 minTopHash 时候，自动将其值加上 minTopHash 作为该 key 的 tophash。

**在实际运行过程中**，bmap 由 tophash 和连续的键、值数组组成，每个键值对占用一个槽位。overflow 存储的是指向溢出桶的指针，使用 uintptr 类型而非 *bmap 是为了**避免被 GC 扫描**到。类似于这样：

```go
type bmap struct {
    tophash  [8]uint8
    keys     [8]keytype  // 对应的键类型
    values   [8]elemtype // 对应的值类型
    overflow uintptr
}
```



- 

#### Map 哈希冲突

map 哈希冲突的解决方案是使用**链地址法**。不过这里的链表单元并不是一个元素，而是**桶**。

#### Map 扩容

Go 1.18 后，map 的负载因子是根据实际的哈希表性能来**动态调整**的。map 的负载因子调整分为两个方面：添加元素时的扩容、删除元素时的缩容。

- 在添加元素时的扩容阶段，当 map 中的元素个数达到当前桶数量和负载因子的乘积时，Go 的 map 实现会进行负载因子调整。具体调整步骤如下：
  - 计算当前哈希表的性能指标，主要是通过测量平均查找时间来评估；
    如果当前哈希表的平均查找时间小于桶的填充因子（即平均查找时间小于等于 6.5），则会增加负载因子，具体增加的比例为当前负载因子的 5%；
    根据新的负载因子重新计算桶的数量，保证桶的数量为 2 的幂次方。

- 在删除元素时的缩容阶段，当 map 中的元素个数小于当前桶数量和负载因子的乘积的一半时，会进行负载因子调整。具体调整步骤如下：
  - 计算当前哈希表的性能指标，同样是通过测量平均查找时间来评估；
    如果当前哈希表的平均查找时间小于桶的填充因子（即平均查找时间小于等于 6.5），则会减少负载因子。具体减少的比例为当前负载因子的 5%；
    根据新的负载因子重新计算桶的数量，保证桶的数量为 2 的幂次方。

由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果 map 存储了数以亿计的 key/value，一次性搬迁将会造成比较大的延时

**渐进式扩容**

原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket

#### Map 并发相关

map 默认是并发不安全的，同时对 map 进行并发读写时，程序会抛出 fatal error: concurrent map writes，原因如下：

Go 官方在经过了长时间的讨论后，认为 map 更应适配典型使用场景（不需要从多个 goroutine 中进行安全访问），而不是为了小部分情况（并发访问），导致大部分程序付出加锁代价（性能），决定了不支持。

##### 读写锁RWMutex

##### sync.map

一种并发安全的map类型，它可以在多个goroutine之间安全地进行读写操作，而不需要额外的同步机制。主要由两个内部map组成：一个用于**读取操作**，一个用于**写入操作**。这样可以减少锁的竞争，提高性能。但是，这也导致了sync.Map的一些缺点：

- sync.Map不能获取当前的元素个数，也不能清空所有的元素。
- sync.Map的内存占用较大，因为它需要维护两个map，并且有一些冗余的数据。
- sync.Map的性能在某些场景下可能不如普通的map加锁，例如当写入操作远多于读取操作时。

**因此，最好只是在读多写少或各协程操作的key集合交集少时使用sync.map**

> - sync.Map不需要初始化，直接声明即可使用。例如：var m sync.Map
> - sync.Map不能使用map的方式进行取值和设置等操作，而是使用sync.Map的方法进行调用。sync.Map提供了以下几个方法：
>   - Store(key, value interface{})：将键值对存储到sync.Map中。
>   - Load(key interface{}) (value interface{}, ok bool)：根据键从sync.Map中获取对应的值，如果存在则返回值和true，否则返回nil和false。
>   - Delete(key interface{})：根据键从sync.Map中删除对应的键值对。
>   - Range(f func(key, value interface{}) bool)：遍历sync.Map中的所有键值对，对每个键值对调用给定的函数f，如果f返回false，则停止遍历。
>   - LoadOrStore(key, value interface{}) (actual interface{}, loaded bool)：根据键从sync.Map中获取对应的值，如果存在则返回值和true，否则将键值对存储到sync.Map中，并返回值和false。



#### Map 无序遍历

map 因扩张⽽重新哈希时，各键值项存储位置都可能会发生改变，顺序自然也没法保证了，所以官方避免大家依赖顺序，直接打乱处理。就是 for range map 在开始处理循环逻辑的时候，就做了随机播种

```go
// decide where to start
r := uintptr(fastrand())
if h.B > 31-bucketCntBits {
	r += uintptr(fastrand()) << 31
}
it.startBucket = r & bucketMask(h.B)
it.offset = uint8(r >> h.B & (bucketCnt - 1))
```

所以，**是使用快速随机算法随机选了一个桶作为起始桶，并且又快速随机地选择了桶内的任意一个偏移的元素作为起始元素**。

在迭代的时候，如果桶内 `offset + i` 处的元素是空的话，就会 `continue` 跳到下一个元素

```go
offi := (i + it.offset) & (bucketCnt - 1)
if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty {
	// TODO: emptyRest is hard to use here, as we start iterating
	// in the middle of a bucket. It's feasible, just tricky.
	continue
}
```

#### Map插入的时间、空间复杂度

取决于以下几个因素：

- Map的**元素类型**：不同类型的元素可能占用不同大小的内存空间，影响Map的存储效率和哈希计算效率。
- Map的**元素数量**：元素数量越多，可能导致哈希冲突越多，影响Map的查找和插入效率。
- Map的**负载因子**：负载因子是指Map中元素数量与哈希桶数量之比，负载因子越高，可能导致哈希冲突越多，影响Map的查找和插入效率。
- Map的**扩容策略**：当Map中元素数量超过一定阈值时，Map会进行扩容操作，即重新分配一个更大的哈希桶数组，并将原来的元素复制到新的数组中。扩容操作会消耗额外的时间和空间，但可以降低负载因子，提高Map的查找和插入效率。

具体来说：

- Go语言的Map使用了一种**动态扩容机制**，当负载因子达到6.5时（**1.18后，map 的负载因子根据哈希表的性能动态调整**），会触发扩容操作，新数组的大小一般是旧数组的两倍。扩容操作不会一次性完成，而是**分批进行**，**每次读写Map时都会搬迁部分元素**。
- Go语言的Map使用了一种**随机哈希算法**，每个Map都有一个**随机种子**，在计算元素哈希值时会与该种子异或，从而降低哈希冲突的概率。
- Go语言的Map使用了一种**链地址法**来解决哈希冲突，每个哈希桶可以存放8个元素，如果超过了8个，则会链接到一个溢出桶中。溢出桶也可以链接到其他溢出桶中，形成一个链表。
- Go语言的Map在创建时可以指定一个**预期大小（hint）**，这可以提高Map的空间利用率和插入效率。如果不指定预期大小，则默认为0。

综上所述，Go语言的Map的插入操作的时间复杂度和空间复杂度如下：

- 平均情况下，**时间复杂度为O(1)，空间复杂度为O(n)**，其中n为元素数量。
- 最坏情况下，时间复杂度为O(n)，空间复杂度为O(n)，其中n为元素数量。这种情况可能发生在以下几种情况：
  - 所有元素都映射到同一个哈希桶中，导致链表过长。
  - Map进行扩容操作时，需要复制所有元素到新数组中。
  - Map使用了非常大或非常小的预期大小（hint），导致空间浪费或频繁扩容。

#### key 的类型

**在go规范中，可比较的类型都可以作为map key；**这个问题又延伸到：go规范中，哪些数据类型可以比较？

**不能作为map key 的类型包括：**

- slices
- maps
- functions

#### 删除一个 key，它的内存会释放吗？

**具体和GC相关**

如果删除的元素是值类型，如int，float，bool，string以及数组和struct，map的内存不会自动释放

如果删除的元素是引用类型，如指针，slice，map，chan等，map的内存会自动释放，但释放的内存是子元素应用类型的内存占用

将map设置为nil后，内存被回收。

#### nil map 和空 map 

- 可以对未初始化的map进行取值，但取出来的东西是空：

```go
var m1 map[string]string
fmt.Println(m1["1"])
```

- 不能对未初始化的map进行赋值，这样将会抛出一个异常：

```go
var m1 map[string]string
m1["1"] = "1"
panic: assignment to entry in nil map
```

- 通过fmt打印map时，空map和nil map结果是一样的，都为map[]。所以，这个时候别断定map是空还是nil，而应该通过map == nil来判断。

**nil map 未初始化，空map是长度为空**



### 3、Channel

channel（通道）用于 goroutine（协程）之间的通信。它提供了一种在不同协程之间传递数据的机制。channel 是一种类型安全的、阻塞的、先进先出（FIFO）的数据结构，确保发送的数据按照发送的顺序接收。

Go 语言提倡**通过通信来共享内存**，CSP (Communicating Sequential Process) 并发模型，就是通过 goroutine 和 channel 来实现的。

#### 底层实现

##### hchan

通过 var 声明或者 make 函数创建的 channel 变量是一个存储在函数栈帧上的指针，指向堆上的 hchan 结构体。

由**互斥锁**保证并发安全，见最后一行

```go
// src/runtime/chan.go

type hchan struct {
    qcount   uint     // 循环数组中的元素数量
    dataqsiz uint     // 循环数组的长度
    // channel 分为无缓冲和有缓冲两种。
    // 对于有缓冲的 channel 存储数据，使用了 ring buffer（环形缓冲区）来缓存写入的数据，本质是循环数组。
    // 为什么是循环数组？普通数组不行吗？
    // 普通数组容量固定，更适合指定的空间，弹出元素时，普通数组需要全部都前移。
    buf      unsafe.Pointer // 指向底层循环数组的指针（环形缓冲区）
    elemsize uint16   // 元素的大小
    closed   uint32   // channel是否关闭的标志
    elemtype *_type   // channel中的元素类型
    // 当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置
    sendx    uint           // 下一次写下标的位置
    recvx    uint           // 下一次读下标的位置    
    // 尝试读/写 channel 被阻塞的 goroutine
    recvq    waitq  // 读等待队列
    sendq    waitq  // 写等待队列

	lock mutex //互斥锁，保证读写 channel 时不存在并发竞争问题
}
```

##### sudog

等待队列是**双向链表**结构，每个节点是一个 sudog 结构体变量，记录哪个协程在等待，等待的是哪个 channel，等待发送 / 接收的数据在哪里。

```go
// $GOROOT/src/runtime/chan.go
type waitq struct {
    first *sudog
    last  *sudog
}

type sudog struct {
    g *g

    next *sudog
    prev *sudog
    elem unsafe.Pointer 

    ...

    c *hchan 
}
```

#### 阻塞式数据接收流程

- 如果 channel 的写等待队列**存在**发送者 goroutine
  - 如果是无缓冲 channel，直接从第一个发送者 goroutine 那里把数据拷贝给接收变量，唤醒发送的 goroutine
  - 如果是有缓冲 channel（已满），将循环数组 buf 的队首元素拷贝给接收变量，将第一个发送者 goroutine 的数据拷贝到 buf 循环数组队尾，唤醒发送的 goroutine
- 如果 channel 的写等待队列**不存在**发送者 goroutine
  - 如果循环数组 buf 非空，将循环数组 buf 的队首元素拷贝给接收变量
  - 如果循环数组 buf 为空，这个时候就会走阻塞接收的流程，将当前 goroutine 加入读等待队列，并挂起等待唤醒

#### 有缓冲与无缓冲？

- **有缓冲channel**：指创建channel时指定了一个缓冲区大小，可以在缓冲区未满时向channel发送数据，也可以在缓冲区非空时从channel接收数据，不会阻塞当前的goroutine。有缓冲channel可以提高并发性能，适用于生产者和消费者速度不一致的场景。
- **无缓冲channel**：指创建channel时没有指定缓冲区大小，或者大小为0，这时向channel发送数据或从channel接收数据都需要另一端同时就绪，否则会阻塞当前的goroutine。无缓冲channel可以实现同步和互斥，适用于生产者和消费者速度一致的场景。

#### 什么时候会panic？

| 操作 | 未初始化                        | 关闭                               | 正常             |
| ---- | ------------------------------- | ---------------------------------- | ---------------- |
| 关闭 | **panic**: close of nil channel | **panic**: close of closed channel | 正常关闭         |
| 发送 | 永远阻塞导致死锁                | **panic**                          | 阻塞或者成功发送 |
| 接收 | 永远阻塞导致死锁                | 缓冲区空为零值，否则可继续读       | 阻塞或者成功接收 |

- **关闭一个只接收的channel**：如果一个channel是只接收的（例如通过chan<-类型声明），那么对它调用close函数会引发panic。

### 4、Select

它用于在多个通信操作中选择一个可执行的操作进行处理。下面是select的原理和底层实现的简要介绍：

**原理**

1. select语句类似于switch语句，但是它的每个case表示一个通信操作，可以是发送或接收操作。
2. select会等待其中一个case中的通信操作可以进行时，执行该case对应的代码块。如果有多个case同时可以进行，它们会通过一定的策略进行选择，如随机选择一个case。
3. 如果没有任何一个case的通信操作可以进行，且存在default语句，那么会执行default语句对应的代码块。如果没有default语句，select语句将被阻塞，直到至少有一个case可以进行。

**底层实现**

1. select语句的底层实现依赖于Go语言运行时系统中的调度器和通信机制。
2. 在编译时，编译器会将select语句转换为一个状态机。该状态机由调度器来管理和执行。
3. 调度器会监视每个case中的通信操作，并选择其中一个可以进行的操作进行执行。
4. 调度器使用类似于事件循环的机制来检查和处理通信操作的可执行性，以确保只有一个case被执行。
5. select语句的执行过程是非阻塞的，即使某个case被执行，其他case的通信操作也不会受到影响。

### 5、Context

**主要的应用 **

- 上下文控制

- 多个 goroutine 之间的数据交互等

- 超时控制：到某个时间点超时，过多久超时。

context包构建了**树型**关系的Context。go Context底层实际上是通过使用 ***channel + mutex*** 来实现的。**channel负责在父级节点`cancel()`后的相关子协程之间广播通信，而mutex则保证了ctx在多个 goroutine 之间传递时的线程安全。**

使用context时，首先要创建一个顶级的context，也就是`context.Background()`

每次用户请求到来时，向一组具有上下文关系的 *goroutine* 中分别传入***ctx*** 参数，并分别监听ctx.Done()方法。

`Done()`方法返回一个**只读的channel**，所有相关函数监听此channel。一旦channel关闭，所有负责监听的 *goroutine* 通过Go channel被关闭时的**广播机制**，都能够收到通知。

子goroutine可以通过 select-case 的方式检查自身是否被父级节点`cancel()`，一旦上层环境（父节点）撤销了本 *goroutine* 的执行，应当终止对当前请求信息的处理，释放资源并return。

正因为上述方式，一个request范围内所有 *goroutine* 运行时的取消能得到有效控制。

1. Context的底层实现使用了一种称为"传播机制"的技术，它通过将Context对象传递给相关的协程（goroutine）来实现上下文的传递和控制。
2. Context对象是不可变的，一旦创建就不能修改其值。当需要传递上下文时，可以通过派生（Derive）一个新的Context对象，并在派生过程中传递需要的值和属性。
3. Context对象中包含了一个取消信号（Cancellation Signal），它用于向相关的协程发送取消请求。当取消信号被触发时，相关的协程可以相应地进行清理操作并退出。
4. Context对象还可以设置超时时间，一旦超过指定的时间，上下文会自动触发取消操作。
5. Context对象还可以存储一些键值对的数据，这些数据可以在整个上下文树中进行传递和访问。

### 6、Struct

**内存对齐**

1. 字段的大小是由字段的类型决定的，例如**int64类型的字段占用8个字节**。
2. 结构体的对齐大小是结构体中**最大字段大小的倍数**。
3. 结构体的总大小是**对齐大小的倍数**，即结构体的大小必须是对齐大小的整数倍。
4. 如果结构体中的字段大小不是对齐大小的整数倍，编译器会在字段之间插入填充字节（padding），以满足对齐要求。

**空结构体**

- 零内存占用
- 地址不变

根据 malloc.go 源码的部分内容，当要分配的对象大小 size 为 0 时，会返回指向 **zerobase** 的指针。zerobase 是一个用于分配零字节对象的**基准地址**，它不占用任何实际的内存空间。

**使用场景**

- 占位符
  当我们将 map 的值置为空结构体 var m map[K comparable]struct{}，这样无论是作为一个 set 来使用或者判断特定的 key 是否初始化等场景，都能起到节省内存的作用。

- 用于 channel 通信
  go 标准库 context 的 Context 接口的 Done 方法就返回了一个只读 channel，channel 的元素就是空结构体。

- 作为方法接收器
  当方法的实现不需要任何数据存储 / 处理时，可以使用空结构体。

## 底层

### GMP调度模型

GMP调度模型是Go语言中实现协程调度的一种机制，它由三个部分组成：

- G：代表协程，是一个轻量级的执行单元，可以在用户态进行切换和调度。
- M：代表线程，是操作系统内核态的执行单元，可以运行在多核CPU上。
- P：代表处理器，是一个逻辑概念，它维护了一个可运行的协程队列和一些运行时的信息，可以被绑定到一个线程上。

GMP调度模型的基本思想是：

- 每个P都有一个本地队列，用来存放等待运行的G，每个P最多可以同时绑定一个M和一个G。
- 当一个M上的G执行完毕或者被阻塞时，M会从P的本地队列或者全局队列中获取一个新的G来执行，如果队列为空，则会从其他P的本地队列中**偷取一半**的G。
- 当一个M上没有可运行的G时，M会释放绑定的P，并加入到空闲M列表中，等待被唤醒。
- 当系统中有新的G被创建时，它会优先加入到当前M绑定的P的**本地队列**中，如果队列已满，则会把一半的G转移到**全局队列**中。
- 当系统中有新的事件发生时，例如网络I/O、系统调用、信号处理等，会创建一个特殊的G来处理这些事件，并唤醒一个空闲的M或者创建一个新的M来执行这个G。

**关于 G,P,M 的个数问题**

G 的个数理论上是无限制的，但是受内存限制

P 的数量一般建议是逻辑 CPU 数量的 2 倍

M 的数据默认启动的时候是 10000，但内核很难支持这么多线程数，M 一般都是要大于 P。

#### 抢占式调度

1. **系统调用和函数调用边界**：Go 语言的调度器会在系统调用或者特定的函数调用边界进行抢占。当 goroutine 执行系统调用或者函数调用时，调度器会检查是否有其他 goroutine 等待执行，并决定是否将当前 goroutine 暂停，切换到其他可执行的 goroutine 上。
2. **抢占点**：Go 语言的编译器会在一些代码位置插入抢占点。抢占点是指在这些位置上，编译器会插入代码来检查是否需要进行 goroutine 的切换。抢占点通常包括函数调用、循环等代码块的入口处。
3. **时间片**：每个 goroutine 在执行时会被分配一个时间片，时间片用完后，调度器会暂停当前 goroutine，并切换到其他等待执行的 goroutine 上。这种方式可以确保每个 goroutine 都能够获得公平的执行机会。

需要注意的是，抢占式调度**并不是真正的硬件级别的抢占**，而是在 goroutine 主动放弃执行权或者在抢占点进行切换。这种协作抢占的方式相对于硬件级别的抢占更加轻量和高效，避免了线程切换的开销

### GC

#### 垃圾回收过程

1. **标记**（Marking）阶段：这是标记清除算法的关键阶段，用于标记不再使用的对象。在标记阶段，可以通过并发执行来遍历和标记对象，而不需要全局停顿。
2. **根扫描**（Root Scanning）阶段：在并发执行的标记阶段之后，需要扫描根对象，将根对象作为起点，遍历并标记其可达的对象。根扫描阶段需要**启动STW**，以确保在扫描过程中不会有新的根对象被创建或删除。
3. **重新标记**（Reclaiming）阶段：在根扫描阶段之后，可能会有一小部分对象在并发执行期间被标记为不再使用，因此需要进行重新标记。重新标记阶段通常需要**启动STW**，以确保标记的准确性。
4. **清除**（Sweeping）阶段：在完成重新标记阶段后，会**启动STW**来执行清除操作。清除阶段会遍历整个堆，将未标记的对象进行释放，回收内存空间。

#### GC 的触发时机

分为系统触发和主动触发。

- gcTriggerHeap：当所分配的堆大小达到阈值（由控制器计算的触发堆的大小）时，将会触发。

- gcTriggerTime：当距离上一个 GC 周期的时间超过一定时间时，将会触发。时间周期以runtime.forcegcperiod 变量为准，默认 2 分钟。

- gcTriggerCycle：如果没有开启 GC，则启动 GC。

- 手动触发的 runtime.GC 方法。

#### 为什么Go的GC还是老旧的标记-清除？而不是和java一样使用分代算法？

Go的逃逸分析会把大部分新生对象放在栈上，而GC是针对堆的，分代效果不大。

标记清除算法可以在垃圾回收过程中并发执行，不用STW

### 内存相关

#### 内存模式

Go 程序启动的时候申请一大块内存，并且划分 spans，bitmap，areana 区域；arena 区域按照页划分成一个个小块，span 管理一个或者多个页，mcentral 管理多个 span 供现场申请使用；mcache 作为线程私有资源，来源于 mcentral。

Go语言的内存模式是基于**TCMalloc算法**的，它将可用的**堆内存**采用二级分配的方式进行管理：

- 每个线程都会自行维护一个独立的内存池，称为**mcache**，用于分配小对象；
- 当内存池不足时，会向全局的内存池**mcentral**，申请更多的内存；
- mcentral管理着一系列的**mspan**，mspan是由一组连续的页组成的内存块，按照不同的大小划分成**object**，object是实际存储对象的单元；
- mcentral会根据object的大小分为不同的**size class**，以便快速查找和分配；
- 当mcentral也不足时，会向操作系统申请更多的内存，这部分内存由**mheap**管理，mheap维护着整个虚拟内存空间和物理内存空间的映射关系。

Go语言还有一个垃圾回收器（GC），用于定期清理不再使用的内存空间，它采用了三色标记清除算法，并且实现了并发和低延迟的特性。

#### 内存逃逸

本该分配到栈上的变量，跑到了堆上，这就导致了内存逃逸。

栈是高地址到低地址，栈上的变量，函数结束后变量会跟着回收掉，不会有额外性能的开销。

变量从栈逃逸到堆上，如果要回收掉，需要进行 gc，那么 gc 一定会带来额外的性能开销。

编程语言不断优化 gc 算法，主要目的都是为了减少 gc 带来的额外性能开销，变量一旦逃逸会导致性能开销变大。

**内存逃逸的情况如下：**

- 方法内返回局部变量指针。

- 向 channel 发送指针数据。

- 在闭包中引用包外的值。

- 在 slice 或 map 中存储指针。

- 切片（扩容后）长度太大。

- 在 interface 类型上调用方法。

#### 内存泄露

go 中的内存泄漏一般都是 goroutine 泄漏，就是 goroutine 没有被关闭，或者没有添加超时控制，让 goroutine 一只处于阻塞状态，不能被 GC。

**内存泄露有下面一些情况**

- 如果 goroutine 在执行时被阻塞而无法退出，就会导致 goroutine 的内存泄漏，一个 goroutine 的最低栈大小为 2KB，在高并发的场景下，对内存的消耗也是非常恐怖的。

- 互斥锁未释放或者造成死锁会造成内存泄漏

- time.Ticker 是每隔指定的时间就会向通道内写数据。作为循环触发器，必须调用 stop 方法才会停止，从而被 GC 掉，否则会一直占用内存空间。

- 字符串的截取引发临时性的内存泄漏

```text
func main() {
	var str0 = "12345678901234567890"
	str1 := str0[:10]
}
```

- 切片截取引起子切片内存泄漏

```text
func main() {
	var s0 = []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
	s1 := s0[:3]
}
```

- 函数数组传参引发内存泄漏

  【如果我们在函数传参的时候用到了数组传参，且这个数组够大（我们假设数组大小为 100 万，64 位机上消耗的内存约为 800w 字节，即 8MB 内存），或者该函数短时间内被调用 N 次，那么可想而知，会消耗大量内存，对性能产生极大的影响，如果短时间内分配大量内存，而又来不及 GC，那么就会产生临时性的内存泄漏，对于高并发场景相当可怕。】

**排查方式：**

一般通过 **pprof** ， Go 的性能分析工具，在程序运行过程中，可以记录程序的运行信息，可以是 **CPU 使用情况、内存使用情况、goroutine 运行情况**等，当需要性能调优或者定位 Bug 时候，这些记录的信息是相当重要。

### 并发、锁相关

#### Mutex悲观锁

**悲观锁**

当要对数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制，在修改数据之前先锁定，再修改的方式被称之为悲观并发控制【Pessimistic Concurrency Control，缩写“PCC”，又名“悲观锁”】。

**乐观锁**

乐观锁的一个常见实现是使用`sync.atomic` 包提供的原子操作函数，如`atomic.CompareAndSwapInt32`。这些原子操作函数可以在不使用互斥锁的情况下实现并发安全的数据访问。

乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果冲突，则返回给用户异常信息，让用户决定如何去做。乐观锁适用于读多写少的场景，这样可以提高程序的吞吐量

#### Mutex 模式

**正常模式**

1. 当前的mutex只有一个goruntine来获取，那么没有竞争，直接返回。
2. 新的goruntine进来，如果当前mutex已经被获取了，则该goruntine进入一个先入先出的waiter队列，在mutex被释放后，waiter按照先进先出的方式获取锁。该goruntine会处于自旋状态(不挂起，继续占有cpu)。
3. 新的goruntine进来，mutex处于空闲状态，将参与竞争。新来的 goroutine 有先天的优势，它们正在 CPU 中运行，可能它们的数量还不少，所以，在高并发情况下，被唤醒的 waiter 可能比较悲剧地获取不到锁，这时，它会被插入到队列的前面。如果 waiter 获取不到锁的时间超过阈值 1 毫秒，那么，这个 Mutex 就进入到了饥饿模式。

**饥饿模式**

在饥饿模式下，Mutex 的拥有者将直接把锁交给队列最前面的 waiter。新来的 goroutine 不会尝试获取锁，即使看起来锁没有被持有，它也不会去抢，也不会 spin（自旋），它会乖乖地加入到等待队列的尾部。 如果拥有 Mutex 的 waiter 发现下面两种情况的其中之一，它就会把这个 Mutex 转换成正常模式:

1. 此 waiter 已经是队列中的最后一个 waiter 了，没有其它的等待锁的 goroutine 了；
2. 此 waiter 的等待时间小于 1 毫秒。

#### Atomic包的原子操作

`atomic.CompareAndSwapInt32`函数是Go语言标准库提供的原子操作函数，它在底层实现中使用了**硬件层面**（通常使用CPU的`CMPXCHG`指令）的CAS操作来实现原子性。CAS操作是一个底层的**原语**（primitive），用于实现并发环境下的原子性操作。

虽然`atomic.CompareAndSwapInt32`函数本身已经提供了原子性的比较和交换操作，但为了实现更复杂的并发逻辑，可以加以使用`atomic.LoadInt32`和`atomic.StoreInt32`。

- `atomic.LoadInt32`函数用于原子地加载（**读取**）指定地址处的32位整数值，并返回该值。它可以用于读取共享变量的当前值，以便进行后续的计算或判断。

- `atomic.StoreInt32`函数用于原子地存储（**写入**）指定地址处的32位整数值。它可以用于将新值写入到共享变量，以更新共享状态。
  - 需要注意的是，`atomic.LoadInt32`和`atomic.StoreInt32`函数本身并不是CAS操作

### netpoller

netpoller是Go语言中实现网络I/O多路复用的一个组件，是runtime的内部机制，用来监听和分发网络事件，从而提高程序的并发性能。netpoller的数据结构和底层运行的过程和原理如下：

- netpoller的数据结构主要包括两个部分：一个是netpollBreaker，用来唤醒阻塞在epoll_wait上的线程；另一个是pollDesc，用来存储每个文件描述符（fd）的状态和回调函数。
- netpoller的底层运行依赖于操作系统提供的I/O多路复用技术，例如Linux上的epoll，Windows上的iocp（可用于文件IO），MacOS上的kqueue等。netpoller会创建一个epoll实例，并将需要监听的fd加入到epoll中，同时注册相应的回调函数。
- netpoller会在后台启动一个**线程**（netpoller线程），用来执行epoll_wait函数，阻塞等待网络事件的发生。
  - 当有网络事件发生时，epoll_wait会返回相应的fd和事件类型，netpoller线程会根据fd找到对应的pollDesc，并调用其回调函数。
- netpoller的回调函数主要有两种：netpollready和netpolldeadline。netpollready用来处理网络I/O就绪事件，它会将对应的协程从等待队列中移除，并加入到就绪队列中，等待调度器进行调度。netpolldeadline用来处理网络I/O超时事件，它会关闭对应的fd，并将对应的协程从等待队列中移除，并加入到就绪队列中，等待调度器进行调度。
- netpoller还提供了一些辅助函数，例如netpoll、netpollblock、netpollopen、netpollclose等，用来控制fd的监听状态和超时时间，以及与协程和调度器之间的交互。

### Go 多返回值实现

Go 传参和返回值是通过 FP+offset 实现，并且存储在调用函数的栈帧中。FP 栈底寄存器，指向一个函数栈的顶部;PC 程序计数器，指向下一条执行指令;SB 指向静态数据的基指针，全局符号;SP 栈顶寄存器。

### Go 不同类型比较是否相等

-  string，int，float ，interface 等可以通过 reflect.DeepEqual 和**等于号**进行比较

-  slice，struct，map 则一般使用 reflect.DeepEqual 来检测是否相等。